{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of final_test_tom_jerry_submission_1_f1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDlSqVRGDPRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Co7BByBD75l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8Q5Mx1dEAVM",
        "colab_type": "code",
        "outputId": "ff9f3923-8cf0-4f84-9b2c-e63fddc26d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "faces = []\n",
        "path= '/content/drive/My Drive/SMAI_Final_Assignment/Q2/train/ntrain/'\n",
        "data = pd.read_csv('/content/drive/My Drive/SMAI_Final_Assignment/Q2/train_data.csv')\n",
        "for i in data['image_file']:\n",
        "    location = path + i + '.jpg'\n",
        "    location = location.strip()\n",
        "    img = cv2.imread(location, 0)\n",
        "    img = cv2.resize(img, (128,128), interpolation = cv2.INTER_AREA)\n",
        "    faces.append(img)\n",
        "\n",
        "faces = np.array(faces)\n",
        "X_train = faces.reshape(faces.shape[0], 128, 128, 1)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1941, 128, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8iLRva_RpGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = []\n",
        "for i in data['emotion']:\n",
        "    y.append(i)\n",
        "\n",
        "number_of_classes = len(set(y))\n",
        "# print(number_of_classes)  \n",
        "y_train = np.array(y)\n",
        "y_train = y_train.astype('float32')\n",
        "y_train = keras.utils.to_categorical(y_train, number_of_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DedrZo2dFIg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X_train\n",
        "y = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v33FR-nRa6dq",
        "colab_type": "code",
        "outputId": "ca4e413e-02de-4e9b-d627-a5f871736a71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "faces.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1941, 128, 128, 1)\n",
            "(1941, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1941, 128, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amWArkUddD7B",
        "colab_type": "text"
      },
      "source": [
        "# Train validation data split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhYeCnjaUT7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, train_size = 0.80)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WiR_o6BwmuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = []\n",
        "for row in y_test:\n",
        "  y_true.append((row.tolist()).index(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtMiV-rmFR-e",
        "colab_type": "text"
      },
      "source": [
        "## MLP models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUZlRbb1ZaXB",
        "colab_type": "text"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep5A0iEcC-9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(128, (3, 3), input_shape=(128, 128, 1), activation = 'relu'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(5, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6xXP9MSDGbr",
        "colab_type": "code",
        "outputId": "febd69f3-1d71-4c12-d25c-ee909d453787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 16.6810 - accuracy: 0.2564\n",
            "Epoch 2/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 1.8547 - accuracy: 0.2822\n",
            "Epoch 3/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 1.6564 - accuracy: 0.3557\n",
            "Epoch 4/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 1.3186 - accuracy: 0.4794\n",
            "Epoch 5/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 1.0830 - accuracy: 0.6211\n",
            "Epoch 6/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 1.1113 - accuracy: 0.6585\n",
            "Epoch 7/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.7005 - accuracy: 0.7700\n",
            "Epoch 8/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.6504 - accuracy: 0.7854\n",
            "Epoch 9/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.5197 - accuracy: 0.8235\n",
            "Epoch 10/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.4441 - accuracy: 0.8653\n",
            "Epoch 11/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.3638 - accuracy: 0.8853\n",
            "Epoch 12/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.3856 - accuracy: 0.8737\n",
            "Epoch 13/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.3040 - accuracy: 0.9027\n",
            "Epoch 14/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.2897 - accuracy: 0.9079\n",
            "Epoch 15/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.2439 - accuracy: 0.9220\n",
            "Epoch 16/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1922 - accuracy: 0.9330\n",
            "Epoch 17/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1730 - accuracy: 0.9362\n",
            "Epoch 18/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1412 - accuracy: 0.9543\n",
            "Epoch 19/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.7033 - accuracy: 0.9124\n",
            "Epoch 20/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1077 - accuracy: 0.9594\n",
            "Epoch 21/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1093 - accuracy: 0.9639\n",
            "Epoch 22/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1032 - accuracy: 0.9639\n",
            "Epoch 23/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0968 - accuracy: 0.9652\n",
            "Epoch 24/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1093 - accuracy: 0.9613\n",
            "Epoch 25/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0868 - accuracy: 0.9716\n",
            "Epoch 26/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0977 - accuracy: 0.9684\n",
            "Epoch 27/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0798 - accuracy: 0.9723\n",
            "Epoch 28/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0885 - accuracy: 0.9723\n",
            "Epoch 29/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0846 - accuracy: 0.9671\n",
            "Epoch 30/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0579 - accuracy: 0.9807\n",
            "Epoch 31/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0668 - accuracy: 0.9768\n",
            "Epoch 32/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0450 - accuracy: 0.9839\n",
            "Epoch 33/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0736 - accuracy: 0.9762\n",
            "Epoch 34/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0746 - accuracy: 0.9787\n",
            "Epoch 35/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0317 - accuracy: 0.9878\n",
            "Epoch 36/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0529 - accuracy: 0.9832\n",
            "Epoch 37/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0450 - accuracy: 0.9878\n",
            "Epoch 38/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0474 - accuracy: 0.9839\n",
            "Epoch 39/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0417 - accuracy: 0.9858\n",
            "Epoch 40/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0248 - accuracy: 0.9923\n",
            "Epoch 41/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0296 - accuracy: 0.9903\n",
            "Epoch 42/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0479 - accuracy: 0.9858\n",
            "Epoch 43/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0573 - accuracy: 0.9858\n",
            "Epoch 44/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0606 - accuracy: 0.9832\n",
            "Epoch 45/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0279 - accuracy: 0.9910\n",
            "Epoch 46/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0240 - accuracy: 0.9942\n",
            "Epoch 47/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0525 - accuracy: 0.9852\n",
            "Epoch 48/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0363 - accuracy: 0.9865\n",
            "Epoch 49/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0253 - accuracy: 0.9929\n",
            "Epoch 50/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0327 - accuracy: 0.9878\n",
            "Epoch 51/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0206 - accuracy: 0.9916\n",
            "Epoch 52/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1123 - accuracy: 0.9781\n",
            "Epoch 53/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0267 - accuracy: 0.9929\n",
            "Epoch 54/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0209 - accuracy: 0.9929\n",
            "Epoch 55/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0284 - accuracy: 0.9903\n",
            "Epoch 56/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0167 - accuracy: 0.9903\n",
            "Epoch 57/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0131 - accuracy: 0.9955\n",
            "Epoch 58/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0162 - accuracy: 0.9955\n",
            "Epoch 59/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0229 - accuracy: 0.9897\n",
            "Epoch 60/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0223 - accuracy: 0.9955\n",
            "Epoch 61/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0158 - accuracy: 0.9961\n",
            "Epoch 62/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0221 - accuracy: 0.9929\n",
            "Epoch 63/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0186 - accuracy: 0.9955\n",
            "Epoch 64/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0115 - accuracy: 0.9955\n",
            "Epoch 65/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0196 - accuracy: 0.9936\n",
            "Epoch 66/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0160 - accuracy: 0.9961\n",
            "Epoch 67/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0443 - accuracy: 0.9903\n",
            "Epoch 68/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0171 - accuracy: 0.9936\n",
            "Epoch 69/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0169 - accuracy: 0.9948\n",
            "Epoch 70/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0226 - accuracy: 0.9916\n",
            "Epoch 71/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0207 - accuracy: 0.9910\n",
            "Epoch 72/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0346 - accuracy: 0.9916\n",
            "Epoch 73/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0139 - accuracy: 0.9961\n",
            "Epoch 74/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0107 - accuracy: 0.9955\n",
            "Epoch 75/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0132 - accuracy: 0.9948\n",
            "Epoch 76/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0254 - accuracy: 0.9916\n",
            "Epoch 77/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0175 - accuracy: 0.9942\n",
            "Epoch 78/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0168 - accuracy: 0.9948\n",
            "Epoch 79/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0223 - accuracy: 0.9942\n",
            "Epoch 80/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0257 - accuracy: 0.9929\n",
            "Epoch 81/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0061 - accuracy: 0.9968\n",
            "Epoch 82/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0104 - accuracy: 0.9955\n",
            "Epoch 83/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0183 - accuracy: 0.9948\n",
            "Epoch 84/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0179 - accuracy: 0.9929\n",
            "Epoch 85/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0290 - accuracy: 0.9916\n",
            "Epoch 86/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0122 - accuracy: 0.9948\n",
            "Epoch 87/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0044 - accuracy: 0.9987\n",
            "Epoch 88/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0309 - accuracy: 0.9968\n",
            "Epoch 89/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0143 - accuracy: 0.9948\n",
            "Epoch 90/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0258 - accuracy: 0.9942\n",
            "Epoch 91/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0201 - accuracy: 0.9929\n",
            "Epoch 92/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0082 - accuracy: 0.9968\n",
            "Epoch 93/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0228 - accuracy: 0.9948\n",
            "Epoch 94/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0138 - accuracy: 0.9961\n",
            "Epoch 95/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0070 - accuracy: 0.9974\n",
            "Epoch 96/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0164 - accuracy: 0.9961\n",
            "Epoch 97/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0212 - accuracy: 0.9942\n",
            "Epoch 98/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0142 - accuracy: 0.9955\n",
            "Epoch 99/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0063 - accuracy: 0.9974\n",
            "Epoch 100/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0098 - accuracy: 0.9968\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff7836d5c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0ade9426-97d6-4634-ad51-d767edf01a1b",
        "id": "-AARQw3tZB37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "predictions = []\n",
        "for row in y_pred:\n",
        "  predictions.append(np.argmax(row))\n",
        "a1 = accuracy_score(y_true, predictions)\n",
        "f1_1 = f1_score(y_true, predictions, average = 'weighted')\n",
        "print(\"Accuracy: \", a1)\n",
        "print(\"F1 score: \", f1_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8149100257069408\n",
            "F1 score:  0.815544549151315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Hryoysm1ZiTE"
      },
      "source": [
        "# Model 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rVdaOipfZiTW",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3, 3), input_shape=(128, 128, 1), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(5, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9d342446-15aa-4505-88b6-61dda2b71545",
        "id": "nVPTVlgSZiTs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1552/1552 [==============================] - 3s 2ms/step - loss: 6.9266 - accuracy: 0.3138\n",
            "Epoch 2/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 1.6078 - accuracy: 0.3950\n",
            "Epoch 3/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 1.6300 - accuracy: 0.4323\n",
            "Epoch 4/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 1.2977 - accuracy: 0.4865\n",
            "Epoch 5/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 1.1935 - accuracy: 0.5277\n",
            "Epoch 6/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 1.2311 - accuracy: 0.5548\n",
            "Epoch 7/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 1.3920 - accuracy: 0.5715\n",
            "Epoch 8/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 1.0001 - accuracy: 0.6591\n",
            "Epoch 9/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.8004 - accuracy: 0.6965\n",
            "Epoch 10/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.7532 - accuracy: 0.7268\n",
            "Epoch 11/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.6475 - accuracy: 0.7655\n",
            "Epoch 12/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.6499 - accuracy: 0.7758\n",
            "Epoch 13/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.5409 - accuracy: 0.7996\n",
            "Epoch 14/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.5194 - accuracy: 0.8209\n",
            "Epoch 15/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.4462 - accuracy: 0.8415\n",
            "Epoch 16/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.3758 - accuracy: 0.8660\n",
            "Epoch 17/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.3840 - accuracy: 0.8679\n",
            "Epoch 18/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.3689 - accuracy: 0.8698\n",
            "Epoch 19/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.2732 - accuracy: 0.9072\n",
            "Epoch 20/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.2556 - accuracy: 0.9104\n",
            "Epoch 21/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.3312 - accuracy: 0.8956\n",
            "Epoch 22/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.2365 - accuracy: 0.9175\n",
            "Epoch 23/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.2237 - accuracy: 0.9201\n",
            "Epoch 24/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.2177 - accuracy: 0.9253\n",
            "Epoch 25/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1783 - accuracy: 0.9439\n",
            "Epoch 26/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1921 - accuracy: 0.9349\n",
            "Epoch 27/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1682 - accuracy: 0.9414\n",
            "Epoch 28/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1702 - accuracy: 0.9388\n",
            "Epoch 29/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1387 - accuracy: 0.9452\n",
            "Epoch 30/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1348 - accuracy: 0.9568\n",
            "Epoch 31/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1360 - accuracy: 0.9504\n",
            "Epoch 32/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1219 - accuracy: 0.9562\n",
            "Epoch 33/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0933 - accuracy: 0.9633\n",
            "Epoch 34/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1241 - accuracy: 0.9594\n",
            "Epoch 35/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1451 - accuracy: 0.9568\n",
            "Epoch 36/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1083 - accuracy: 0.9568\n",
            "Epoch 37/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0864 - accuracy: 0.9704\n",
            "Epoch 38/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1071 - accuracy: 0.9555\n",
            "Epoch 39/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0965 - accuracy: 0.9659\n",
            "Epoch 40/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0958 - accuracy: 0.9639\n",
            "Epoch 41/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0701 - accuracy: 0.9736\n",
            "Epoch 42/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0956 - accuracy: 0.9639\n",
            "Epoch 43/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0959 - accuracy: 0.9691\n",
            "Epoch 44/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.1034 - accuracy: 0.9639\n",
            "Epoch 45/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0882 - accuracy: 0.9684\n",
            "Epoch 46/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0746 - accuracy: 0.9749\n",
            "Epoch 47/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0612 - accuracy: 0.9794\n",
            "Epoch 48/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0703 - accuracy: 0.9723\n",
            "Epoch 49/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0841 - accuracy: 0.9768\n",
            "Epoch 50/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0689 - accuracy: 0.9742\n",
            "Epoch 51/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0659 - accuracy: 0.9768\n",
            "Epoch 52/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0762 - accuracy: 0.9723\n",
            "Epoch 53/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0693 - accuracy: 0.9762\n",
            "Epoch 54/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0533 - accuracy: 0.9800\n",
            "Epoch 55/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0748 - accuracy: 0.9787\n",
            "Epoch 56/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0512 - accuracy: 0.9787\n",
            "Epoch 57/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0578 - accuracy: 0.9807\n",
            "Epoch 58/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0654 - accuracy: 0.9787\n",
            "Epoch 59/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0637 - accuracy: 0.9697\n",
            "Epoch 60/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0513 - accuracy: 0.9820\n",
            "Epoch 61/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0797 - accuracy: 0.9749\n",
            "Epoch 62/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0477 - accuracy: 0.9852\n",
            "Epoch 63/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0389 - accuracy: 0.9852\n",
            "Epoch 64/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0373 - accuracy: 0.9865\n",
            "Epoch 65/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0580 - accuracy: 0.9852\n",
            "Epoch 66/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0456 - accuracy: 0.9826\n",
            "Epoch 67/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0507 - accuracy: 0.9800\n",
            "Epoch 68/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0524 - accuracy: 0.9774\n",
            "Epoch 69/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0609 - accuracy: 0.9826\n",
            "Epoch 70/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0520 - accuracy: 0.9820\n",
            "Epoch 71/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0481 - accuracy: 0.9813\n",
            "Epoch 72/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0313 - accuracy: 0.9890\n",
            "Epoch 73/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0466 - accuracy: 0.9852\n",
            "Epoch 74/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0590 - accuracy: 0.9826\n",
            "Epoch 75/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0371 - accuracy: 0.9865\n",
            "Epoch 76/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0650 - accuracy: 0.9781\n",
            "Epoch 77/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0590 - accuracy: 0.9826\n",
            "Epoch 78/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0439 - accuracy: 0.9852\n",
            "Epoch 79/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0509 - accuracy: 0.9832\n",
            "Epoch 80/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0349 - accuracy: 0.9858\n",
            "Epoch 81/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0328 - accuracy: 0.9884\n",
            "Epoch 82/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0398 - accuracy: 0.9839\n",
            "Epoch 83/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0430 - accuracy: 0.9865\n",
            "Epoch 84/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0407 - accuracy: 0.9852\n",
            "Epoch 85/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0504 - accuracy: 0.9832\n",
            "Epoch 86/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0464 - accuracy: 0.9832\n",
            "Epoch 87/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0342 - accuracy: 0.9910\n",
            "Epoch 88/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0386 - accuracy: 0.9852\n",
            "Epoch 89/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0312 - accuracy: 0.9845\n",
            "Epoch 90/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0267 - accuracy: 0.9890\n",
            "Epoch 91/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0371 - accuracy: 0.9845\n",
            "Epoch 92/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0366 - accuracy: 0.9897\n",
            "Epoch 93/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0268 - accuracy: 0.9897\n",
            "Epoch 94/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0352 - accuracy: 0.9884\n",
            "Epoch 95/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0409 - accuracy: 0.9852\n",
            "Epoch 96/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0407 - accuracy: 0.9878\n",
            "Epoch 97/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0386 - accuracy: 0.9865\n",
            "Epoch 98/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0266 - accuracy: 0.9884\n",
            "Epoch 99/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0386 - accuracy: 0.9878\n",
            "Epoch 100/100\n",
            "1552/1552 [==============================] - 2s 1ms/step - loss: 0.0435 - accuracy: 0.9871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff7835bca20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c510d698-29c3-4418-cbbe-b7293e232a3c",
        "id": "LBAilt7DZiT4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "predictions = []\n",
        "for row in y_pred:\n",
        "  predictions.append(np.argmax(row))\n",
        "a2 = accuracy_score(y_true, predictions)\n",
        "f1_2 = f1_score(y_true, predictions, average = 'weighted')\n",
        "print(\"Accuracy: \", a2)\n",
        "print(\"F1 score: \", f1_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8174807197943444\n",
            "F1 score:  0.8174173425039601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGDxbibEZpoK",
        "colab_type": "text"
      },
      "source": [
        "# Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV4_QEaqN_x2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(128, (3, 3), input_shape=(128, 128, 1), activation = 'relu'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(5, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_hIBfwZOWqB",
        "colab_type": "code",
        "outputId": "e082de32-7e85-41af-8a59-57764328dc92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 4.4382 - accuracy: 0.3466\n",
            "Epoch 2/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 1.5469 - accuracy: 0.4543\n",
            "Epoch 3/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 1.2122 - accuracy: 0.5412\n",
            "Epoch 4/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 1.1447 - accuracy: 0.5780\n",
            "Epoch 5/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.9473 - accuracy: 0.6521\n",
            "Epoch 6/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.8417 - accuracy: 0.6965\n",
            "Epoch 7/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.7537 - accuracy: 0.7300\n",
            "Epoch 8/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.6618 - accuracy: 0.7719\n",
            "Epoch 9/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.6751 - accuracy: 0.7674\n",
            "Epoch 10/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.5312 - accuracy: 0.8202\n",
            "Epoch 11/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.4714 - accuracy: 0.8402\n",
            "Epoch 12/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.4380 - accuracy: 0.8531\n",
            "Epoch 13/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.4106 - accuracy: 0.8602\n",
            "Epoch 14/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.4087 - accuracy: 0.8589\n",
            "Epoch 15/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.3240 - accuracy: 0.8802\n",
            "Epoch 16/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.3186 - accuracy: 0.8924\n",
            "Epoch 17/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.3098 - accuracy: 0.8963\n",
            "Epoch 18/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.3252 - accuracy: 0.8918\n",
            "Epoch 19/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.2621 - accuracy: 0.9079\n",
            "Epoch 20/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.2577 - accuracy: 0.9066\n",
            "Epoch 21/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.2683 - accuracy: 0.9111\n",
            "Epoch 22/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.2321 - accuracy: 0.9246\n",
            "Epoch 23/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.2173 - accuracy: 0.9246\n",
            "Epoch 24/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1989 - accuracy: 0.9278\n",
            "Epoch 25/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.2009 - accuracy: 0.9246\n",
            "Epoch 26/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1719 - accuracy: 0.9323\n",
            "Epoch 27/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.3683 - accuracy: 0.9091\n",
            "Epoch 28/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1866 - accuracy: 0.9362\n",
            "Epoch 29/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1461 - accuracy: 0.9485\n",
            "Epoch 30/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1543 - accuracy: 0.9401\n",
            "Epoch 31/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1751 - accuracy: 0.9401\n",
            "Epoch 32/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1462 - accuracy: 0.9375\n",
            "Epoch 33/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1654 - accuracy: 0.9362\n",
            "Epoch 34/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1400 - accuracy: 0.9446\n",
            "Epoch 35/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1405 - accuracy: 0.9478\n",
            "Epoch 36/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1480 - accuracy: 0.9459\n",
            "Epoch 37/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1449 - accuracy: 0.9504\n",
            "Epoch 38/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1342 - accuracy: 0.9491\n",
            "Epoch 39/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1212 - accuracy: 0.9485\n",
            "Epoch 40/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1099 - accuracy: 0.9536\n",
            "Epoch 41/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1169 - accuracy: 0.9594\n",
            "Epoch 42/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1220 - accuracy: 0.9536\n",
            "Epoch 43/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1385 - accuracy: 0.9497\n",
            "Epoch 44/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1157 - accuracy: 0.9588\n",
            "Epoch 45/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1077 - accuracy: 0.9588\n",
            "Epoch 46/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1199 - accuracy: 0.9601\n",
            "Epoch 47/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1117 - accuracy: 0.9652\n",
            "Epoch 48/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0852 - accuracy: 0.9704\n",
            "Epoch 49/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1084 - accuracy: 0.9549\n",
            "Epoch 50/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0975 - accuracy: 0.9646\n",
            "Epoch 51/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1042 - accuracy: 0.9620\n",
            "Epoch 52/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1010 - accuracy: 0.9671\n",
            "Epoch 53/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0857 - accuracy: 0.9652\n",
            "Epoch 54/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0881 - accuracy: 0.9716\n",
            "Epoch 55/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0855 - accuracy: 0.9723\n",
            "Epoch 56/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1049 - accuracy: 0.9601\n",
            "Epoch 57/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0722 - accuracy: 0.9691\n",
            "Epoch 58/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1022 - accuracy: 0.9652\n",
            "Epoch 59/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0878 - accuracy: 0.9691\n",
            "Epoch 60/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0705 - accuracy: 0.9742\n",
            "Epoch 61/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0644 - accuracy: 0.9755\n",
            "Epoch 62/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0840 - accuracy: 0.9704\n",
            "Epoch 63/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0803 - accuracy: 0.9723\n",
            "Epoch 64/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0908 - accuracy: 0.9678\n",
            "Epoch 65/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0926 - accuracy: 0.9652\n",
            "Epoch 66/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9729\n",
            "Epoch 67/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.1096 - accuracy: 0.9652\n",
            "Epoch 68/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0780 - accuracy: 0.9742\n",
            "Epoch 69/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0841 - accuracy: 0.9723\n",
            "Epoch 70/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0656 - accuracy: 0.9749\n",
            "Epoch 71/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0736 - accuracy: 0.9749\n",
            "Epoch 72/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9755\n",
            "Epoch 73/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0609 - accuracy: 0.9787\n",
            "Epoch 74/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0701 - accuracy: 0.9749\n",
            "Epoch 75/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0612 - accuracy: 0.9762\n",
            "Epoch 76/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0635 - accuracy: 0.9762\n",
            "Epoch 77/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0744 - accuracy: 0.9781\n",
            "Epoch 78/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0699 - accuracy: 0.9749\n",
            "Epoch 79/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0793 - accuracy: 0.9691\n",
            "Epoch 80/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0729 - accuracy: 0.9762\n",
            "Epoch 81/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0752 - accuracy: 0.9704\n",
            "Epoch 82/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0587 - accuracy: 0.9755\n",
            "Epoch 83/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0580 - accuracy: 0.9762\n",
            "Epoch 84/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0629 - accuracy: 0.9749\n",
            "Epoch 85/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0591 - accuracy: 0.9774\n",
            "Epoch 86/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0440 - accuracy: 0.9813\n",
            "Epoch 87/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0874 - accuracy: 0.9729\n",
            "Epoch 88/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0617 - accuracy: 0.9781\n",
            "Epoch 89/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0754 - accuracy: 0.9723\n",
            "Epoch 90/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0519 - accuracy: 0.9826\n",
            "Epoch 91/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0626 - accuracy: 0.9787\n",
            "Epoch 92/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0633 - accuracy: 0.9807\n",
            "Epoch 93/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0481 - accuracy: 0.9832\n",
            "Epoch 94/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0548 - accuracy: 0.9781\n",
            "Epoch 95/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0609 - accuracy: 0.9800\n",
            "Epoch 96/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0492 - accuracy: 0.9845\n",
            "Epoch 97/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0430 - accuracy: 0.9813\n",
            "Epoch 98/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0510 - accuracy: 0.9807\n",
            "Epoch 99/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0452 - accuracy: 0.9858\n",
            "Epoch 100/100\n",
            "1552/1552 [==============================] - 5s 3ms/step - loss: 0.0494 - accuracy: 0.9813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff783469748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "38f25dc0-a688-47bd-bc4c-be18410ecd0c",
        "id": "40YAQ6Z7Y3_n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "predictions = []\n",
        "for row in y_pred:\n",
        "  predictions.append(np.argmax(row))\n",
        "a3 = accuracy_score(y_true, predictions)\n",
        "f1_3 = f1_score(y_true, predictions, average = 'weighted')\n",
        "print(\"Accuracy: \", a3)\n",
        "print(\"F1 score: \", f1_3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8226221079691517\n",
            "F1 score:  0.8228234823044231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uxjt_6u3aXUt"
      },
      "source": [
        "# Model 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LapHc8c1aXVF",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(128, (3, 3), input_shape=(128, 128, 1), activation = 'relu'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7f37364c-34e9-47b6-f95f-d153efb11a32",
        "id": "8MrSBN_maXVb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 22.7521 - accuracy: 0.2874\n",
            "Epoch 2/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 1.4144 - accuracy: 0.4130\n",
            "Epoch 3/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 1.1267 - accuracy: 0.5941\n",
            "Epoch 4/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.9229 - accuracy: 0.7023\n",
            "Epoch 5/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.7661 - accuracy: 0.7603\n",
            "Epoch 6/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.6063 - accuracy: 0.7996\n",
            "Epoch 7/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.5818 - accuracy: 0.8189\n",
            "Epoch 8/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.4673 - accuracy: 0.8602\n",
            "Epoch 9/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.4088 - accuracy: 0.8782\n",
            "Epoch 10/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.3965 - accuracy: 0.8872\n",
            "Epoch 11/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.3344 - accuracy: 0.9066\n",
            "Epoch 12/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.3191 - accuracy: 0.9104\n",
            "Epoch 13/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.2641 - accuracy: 0.9253\n",
            "Epoch 14/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.2555 - accuracy: 0.9311\n",
            "Epoch 15/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.2190 - accuracy: 0.9356\n",
            "Epoch 16/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.2107 - accuracy: 0.9381\n",
            "Epoch 17/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.2087 - accuracy: 0.9407\n",
            "Epoch 18/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1901 - accuracy: 0.9407\n",
            "Epoch 19/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1773 - accuracy: 0.9459\n",
            "Epoch 20/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1610 - accuracy: 0.9549\n",
            "Epoch 21/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1679 - accuracy: 0.9491\n",
            "Epoch 22/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1665 - accuracy: 0.9568\n",
            "Epoch 23/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1589 - accuracy: 0.9510\n",
            "Epoch 24/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1528 - accuracy: 0.9562\n",
            "Epoch 25/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1609 - accuracy: 0.9530\n",
            "Epoch 26/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1369 - accuracy: 0.9555\n",
            "Epoch 27/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1188 - accuracy: 0.9646\n",
            "Epoch 28/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1365 - accuracy: 0.9613\n",
            "Epoch 29/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1394 - accuracy: 0.9523\n",
            "Epoch 30/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1187 - accuracy: 0.9652\n",
            "Epoch 31/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0996 - accuracy: 0.9697\n",
            "Epoch 32/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.1345 - accuracy: 0.9562\n",
            "Epoch 33/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0946 - accuracy: 0.9697\n",
            "Epoch 34/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0977 - accuracy: 0.9736\n",
            "Epoch 35/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0923 - accuracy: 0.9659\n",
            "Epoch 36/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0974 - accuracy: 0.9671\n",
            "Epoch 37/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0882 - accuracy: 0.9729\n",
            "Epoch 38/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0841 - accuracy: 0.9691\n",
            "Epoch 39/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0950 - accuracy: 0.9697\n",
            "Epoch 40/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0788 - accuracy: 0.9729\n",
            "Epoch 41/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0857 - accuracy: 0.9768\n",
            "Epoch 42/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0896 - accuracy: 0.9755\n",
            "Epoch 43/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0641 - accuracy: 0.9807\n",
            "Epoch 44/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0981 - accuracy: 0.9704\n",
            "Epoch 45/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0855 - accuracy: 0.9704\n",
            "Epoch 46/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0788 - accuracy: 0.9710\n",
            "Epoch 47/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0721 - accuracy: 0.9749\n",
            "Epoch 48/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0699 - accuracy: 0.9755\n",
            "Epoch 49/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0682 - accuracy: 0.9787\n",
            "Epoch 50/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0818 - accuracy: 0.9716\n",
            "Epoch 51/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0688 - accuracy: 0.9742\n",
            "Epoch 52/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0715 - accuracy: 0.9742\n",
            "Epoch 53/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0706 - accuracy: 0.9755\n",
            "Epoch 54/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0673 - accuracy: 0.9762\n",
            "Epoch 55/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0650 - accuracy: 0.9749\n",
            "Epoch 56/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0566 - accuracy: 0.9800\n",
            "Epoch 57/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0605 - accuracy: 0.9800\n",
            "Epoch 58/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0641 - accuracy: 0.9736\n",
            "Epoch 59/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0577 - accuracy: 0.9781\n",
            "Epoch 60/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0544 - accuracy: 0.9820\n",
            "Epoch 61/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0570 - accuracy: 0.9794\n",
            "Epoch 62/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0654 - accuracy: 0.9762\n",
            "Epoch 63/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0455 - accuracy: 0.9832\n",
            "Epoch 64/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0550 - accuracy: 0.9807\n",
            "Epoch 65/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0553 - accuracy: 0.9832\n",
            "Epoch 66/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0493 - accuracy: 0.9832\n",
            "Epoch 67/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0434 - accuracy: 0.9858\n",
            "Epoch 68/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0554 - accuracy: 0.9787\n",
            "Epoch 69/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0600 - accuracy: 0.9813\n",
            "Epoch 70/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0575 - accuracy: 0.9820\n",
            "Epoch 71/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0525 - accuracy: 0.9839\n",
            "Epoch 72/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0492 - accuracy: 0.9800\n",
            "Epoch 73/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0563 - accuracy: 0.9794\n",
            "Epoch 74/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0472 - accuracy: 0.9839\n",
            "Epoch 75/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0504 - accuracy: 0.9820\n",
            "Epoch 76/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0358 - accuracy: 0.9871\n",
            "Epoch 77/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0499 - accuracy: 0.9826\n",
            "Epoch 78/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0351 - accuracy: 0.9871\n",
            "Epoch 79/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0331 - accuracy: 0.9903\n",
            "Epoch 80/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0358 - accuracy: 0.9852\n",
            "Epoch 81/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0341 - accuracy: 0.9845\n",
            "Epoch 82/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0355 - accuracy: 0.9884\n",
            "Epoch 83/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0452 - accuracy: 0.9858\n",
            "Epoch 84/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0378 - accuracy: 0.9852\n",
            "Epoch 85/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0379 - accuracy: 0.9871\n",
            "Epoch 86/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0380 - accuracy: 0.9858\n",
            "Epoch 87/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0452 - accuracy: 0.9832\n",
            "Epoch 88/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0446 - accuracy: 0.9826\n",
            "Epoch 89/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0285 - accuracy: 0.9884\n",
            "Epoch 90/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0346 - accuracy: 0.9858\n",
            "Epoch 91/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0433 - accuracy: 0.9858\n",
            "Epoch 92/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0467 - accuracy: 0.9852\n",
            "Epoch 93/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0304 - accuracy: 0.9903\n",
            "Epoch 94/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0478 - accuracy: 0.9871\n",
            "Epoch 95/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0369 - accuracy: 0.9903\n",
            "Epoch 96/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0418 - accuracy: 0.9839\n",
            "Epoch 97/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0333 - accuracy: 0.9878\n",
            "Epoch 98/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0454 - accuracy: 0.9839\n",
            "Epoch 99/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0256 - accuracy: 0.9910\n",
            "Epoch 100/100\n",
            "1552/1552 [==============================] - 7s 4ms/step - loss: 0.0299 - accuracy: 0.9890\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff782a22ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "aa528519-a897-4e55-e0a7-40eb62dfa3b5",
        "id": "QxOPoWBraXVn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "predictions = []\n",
        "for row in y_pred:\n",
        "  predictions.append(np.argmax(row))\n",
        "a4 = accuracy_score(y_true, predictions)\n",
        "f1_4 = f1_score(y_true, predictions, average = 'weighted')\n",
        "print(\"Accuracy: \", a4)\n",
        "print(\"F1 score: \", f1_4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7866323907455013\n",
            "F1 score:  0.787395859585713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnMBw_-Muj5R",
        "colab_type": "text"
      },
      "source": [
        "# Model 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1qQQdYwQWX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(128, 128, 1), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(number_of_classes, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkkKLs9vQ2Gf",
        "colab_type": "code",
        "outputId": "854ba75a-3ad3-4dad-9370-585c4057ee98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adamax', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1552/1552 [==============================] - 1s 898us/step - loss: 56.6321 - accuracy: 0.2081\n",
            "Epoch 2/100\n",
            "1552/1552 [==============================] - 1s 519us/step - loss: 1.6126 - accuracy: 0.2468\n",
            "Epoch 3/100\n",
            "1552/1552 [==============================] - 1s 526us/step - loss: 1.5960 - accuracy: 0.2165\n",
            "Epoch 4/100\n",
            "1552/1552 [==============================] - 1s 518us/step - loss: 1.6040 - accuracy: 0.2655\n",
            "Epoch 5/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 1.6022 - accuracy: 0.2668\n",
            "Epoch 6/100\n",
            "1552/1552 [==============================] - 1s 518us/step - loss: 1.5947 - accuracy: 0.2751\n",
            "Epoch 7/100\n",
            "1552/1552 [==============================] - 1s 520us/step - loss: 1.5924 - accuracy: 0.2745\n",
            "Epoch 8/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 1.5908 - accuracy: 0.2713\n",
            "Epoch 9/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 1.5835 - accuracy: 0.2822\n",
            "Epoch 10/100\n",
            "1552/1552 [==============================] - 1s 520us/step - loss: 1.5830 - accuracy: 0.2796\n",
            "Epoch 11/100\n",
            "1552/1552 [==============================] - 1s 530us/step - loss: 1.5767 - accuracy: 0.2867\n",
            "Epoch 12/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 1.5690 - accuracy: 0.2887\n",
            "Epoch 13/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 1.5617 - accuracy: 0.3028\n",
            "Epoch 14/100\n",
            "1552/1552 [==============================] - 1s 535us/step - loss: 1.5612 - accuracy: 0.2887\n",
            "Epoch 15/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 1.5498 - accuracy: 0.3144\n",
            "Epoch 16/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 1.5295 - accuracy: 0.3228\n",
            "Epoch 17/100\n",
            "1552/1552 [==============================] - 1s 517us/step - loss: 1.5146 - accuracy: 0.3544\n",
            "Epoch 18/100\n",
            "1552/1552 [==============================] - 1s 516us/step - loss: 1.5144 - accuracy: 0.3466\n",
            "Epoch 19/100\n",
            "1552/1552 [==============================] - 1s 526us/step - loss: 1.4867 - accuracy: 0.3647\n",
            "Epoch 20/100\n",
            "1552/1552 [==============================] - 1s 523us/step - loss: 1.4988 - accuracy: 0.3466\n",
            "Epoch 21/100\n",
            "1552/1552 [==============================] - 1s 520us/step - loss: 1.4642 - accuracy: 0.3705\n",
            "Epoch 22/100\n",
            "1552/1552 [==============================] - 1s 519us/step - loss: 1.4566 - accuracy: 0.3679\n",
            "Epoch 23/100\n",
            "1552/1552 [==============================] - 1s 520us/step - loss: 1.4403 - accuracy: 0.3608\n",
            "Epoch 24/100\n",
            "1552/1552 [==============================] - 1s 516us/step - loss: 1.4019 - accuracy: 0.3795\n",
            "Epoch 25/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 1.3779 - accuracy: 0.3879\n",
            "Epoch 26/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 1.3443 - accuracy: 0.4014\n",
            "Epoch 27/100\n",
            "1552/1552 [==============================] - 1s 520us/step - loss: 1.2964 - accuracy: 0.4098\n",
            "Epoch 28/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 1.2436 - accuracy: 0.4530\n",
            "Epoch 29/100\n",
            "1552/1552 [==============================] - 1s 516us/step - loss: 1.1781 - accuracy: 0.4762\n",
            "Epoch 30/100\n",
            "1552/1552 [==============================] - 1s 525us/step - loss: 1.1451 - accuracy: 0.4852\n",
            "Epoch 31/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 1.1002 - accuracy: 0.5116\n",
            "Epoch 32/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 1.0655 - accuracy: 0.5367\n",
            "Epoch 33/100\n",
            "1552/1552 [==============================] - 1s 523us/step - loss: 1.0439 - accuracy: 0.5387\n",
            "Epoch 34/100\n",
            "1552/1552 [==============================] - 1s 528us/step - loss: 1.0381 - accuracy: 0.5451\n",
            "Epoch 35/100\n",
            "1552/1552 [==============================] - 1s 531us/step - loss: 0.9927 - accuracy: 0.5941\n",
            "Epoch 36/100\n",
            "1552/1552 [==============================] - 1s 523us/step - loss: 0.9587 - accuracy: 0.6063\n",
            "Epoch 37/100\n",
            "1552/1552 [==============================] - 1s 514us/step - loss: 0.9196 - accuracy: 0.6198\n",
            "Epoch 38/100\n",
            "1552/1552 [==============================] - 1s 525us/step - loss: 0.9027 - accuracy: 0.6224\n",
            "Epoch 39/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 0.8725 - accuracy: 0.6263\n",
            "Epoch 40/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 0.8520 - accuracy: 0.6424\n",
            "Epoch 41/100\n",
            "1552/1552 [==============================] - 1s 531us/step - loss: 0.8461 - accuracy: 0.6424\n",
            "Epoch 42/100\n",
            "1552/1552 [==============================] - 1s 517us/step - loss: 0.8001 - accuracy: 0.6695\n",
            "Epoch 43/100\n",
            "1552/1552 [==============================] - 1s 517us/step - loss: 0.8082 - accuracy: 0.6591\n",
            "Epoch 44/100\n",
            "1552/1552 [==============================] - 1s 524us/step - loss: 0.7946 - accuracy: 0.6611\n",
            "Epoch 45/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 0.7714 - accuracy: 0.6714\n",
            "Epoch 46/100\n",
            "1552/1552 [==============================] - 1s 524us/step - loss: 0.7676 - accuracy: 0.6688\n",
            "Epoch 47/100\n",
            "1552/1552 [==============================] - 1s 519us/step - loss: 0.7149 - accuracy: 0.7049\n",
            "Epoch 48/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 0.7173 - accuracy: 0.6869\n",
            "Epoch 49/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 0.7499 - accuracy: 0.6875\n",
            "Epoch 50/100\n",
            "1552/1552 [==============================] - 1s 520us/step - loss: 0.7187 - accuracy: 0.6785\n",
            "Epoch 51/100\n",
            "1552/1552 [==============================] - 1s 517us/step - loss: 0.6923 - accuracy: 0.6933\n",
            "Epoch 52/100\n",
            "1552/1552 [==============================] - 1s 528us/step - loss: 0.6972 - accuracy: 0.6972\n",
            "Epoch 53/100\n",
            "1552/1552 [==============================] - 1s 518us/step - loss: 0.7196 - accuracy: 0.6823\n",
            "Epoch 54/100\n",
            "1552/1552 [==============================] - 1s 527us/step - loss: 0.6969 - accuracy: 0.6933\n",
            "Epoch 55/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 0.6858 - accuracy: 0.6939\n",
            "Epoch 56/100\n",
            "1552/1552 [==============================] - 1s 517us/step - loss: 0.6550 - accuracy: 0.7062\n",
            "Epoch 57/100\n",
            "1552/1552 [==============================] - 1s 518us/step - loss: 0.6747 - accuracy: 0.6939\n",
            "Epoch 58/100\n",
            "1552/1552 [==============================] - 1s 527us/step - loss: 0.6404 - accuracy: 0.7191\n",
            "Epoch 59/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 0.6531 - accuracy: 0.6985\n",
            "Epoch 60/100\n",
            "1552/1552 [==============================] - 1s 530us/step - loss: 0.6223 - accuracy: 0.7197\n",
            "Epoch 61/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 0.6334 - accuracy: 0.7159\n",
            "Epoch 62/100\n",
            "1552/1552 [==============================] - 1s 526us/step - loss: 0.6204 - accuracy: 0.7268\n",
            "Epoch 63/100\n",
            "1552/1552 [==============================] - 1s 527us/step - loss: 0.6065 - accuracy: 0.7229\n",
            "Epoch 64/100\n",
            "1552/1552 [==============================] - 1s 528us/step - loss: 0.6091 - accuracy: 0.7229\n",
            "Epoch 65/100\n",
            "1552/1552 [==============================] - 1s 529us/step - loss: 0.6140 - accuracy: 0.7262\n",
            "Epoch 66/100\n",
            "1552/1552 [==============================] - 1s 534us/step - loss: 0.6089 - accuracy: 0.7178\n",
            "Epoch 67/100\n",
            "1552/1552 [==============================] - 1s 518us/step - loss: 0.5845 - accuracy: 0.7229\n",
            "Epoch 68/100\n",
            "1552/1552 [==============================] - 1s 520us/step - loss: 0.5566 - accuracy: 0.7384\n",
            "Epoch 69/100\n",
            "1552/1552 [==============================] - 1s 518us/step - loss: 0.6012 - accuracy: 0.7229\n",
            "Epoch 70/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 0.5825 - accuracy: 0.7313\n",
            "Epoch 71/100\n",
            "1552/1552 [==============================] - 1s 531us/step - loss: 0.5811 - accuracy: 0.7262\n",
            "Epoch 72/100\n",
            "1552/1552 [==============================] - 1s 526us/step - loss: 0.6075 - accuracy: 0.7113\n",
            "Epoch 73/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 0.5763 - accuracy: 0.7210\n",
            "Epoch 74/100\n",
            "1552/1552 [==============================] - 1s 520us/step - loss: 0.5668 - accuracy: 0.7345\n",
            "Epoch 75/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 0.5690 - accuracy: 0.7287\n",
            "Epoch 76/100\n",
            "1552/1552 [==============================] - 1s 518us/step - loss: 0.5837 - accuracy: 0.7281\n",
            "Epoch 77/100\n",
            "1552/1552 [==============================] - 1s 529us/step - loss: 0.5668 - accuracy: 0.7332\n",
            "Epoch 78/100\n",
            "1552/1552 [==============================] - 1s 530us/step - loss: 0.5508 - accuracy: 0.7352\n",
            "Epoch 79/100\n",
            "1552/1552 [==============================] - 1s 520us/step - loss: 0.5621 - accuracy: 0.7320\n",
            "Epoch 80/100\n",
            "1552/1552 [==============================] - 1s 523us/step - loss: 0.5616 - accuracy: 0.7320\n",
            "Epoch 81/100\n",
            "1552/1552 [==============================] - 1s 524us/step - loss: 0.5718 - accuracy: 0.7320\n",
            "Epoch 82/100\n",
            "1552/1552 [==============================] - 1s 532us/step - loss: 0.5516 - accuracy: 0.7307\n",
            "Epoch 83/100\n",
            "1552/1552 [==============================] - 1s 524us/step - loss: 0.5578 - accuracy: 0.7339\n",
            "Epoch 84/100\n",
            "1552/1552 [==============================] - 1s 525us/step - loss: 0.5565 - accuracy: 0.7358\n",
            "Epoch 85/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 0.5519 - accuracy: 0.7416\n",
            "Epoch 86/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 0.5498 - accuracy: 0.7461\n",
            "Epoch 87/100\n",
            "1552/1552 [==============================] - 1s 523us/step - loss: 0.5097 - accuracy: 0.7571\n",
            "Epoch 88/100\n",
            "1552/1552 [==============================] - 1s 529us/step - loss: 0.5001 - accuracy: 0.7674\n",
            "Epoch 89/100\n",
            "1552/1552 [==============================] - 1s 525us/step - loss: 0.5202 - accuracy: 0.7584\n",
            "Epoch 90/100\n",
            "1552/1552 [==============================] - 1s 524us/step - loss: 0.5271 - accuracy: 0.7494\n",
            "Epoch 91/100\n",
            "1552/1552 [==============================] - 1s 519us/step - loss: 0.4909 - accuracy: 0.7674\n",
            "Epoch 92/100\n",
            "1552/1552 [==============================] - 1s 523us/step - loss: 0.5084 - accuracy: 0.7674\n",
            "Epoch 93/100\n",
            "1552/1552 [==============================] - 1s 520us/step - loss: 0.5056 - accuracy: 0.7642\n",
            "Epoch 94/100\n",
            "1552/1552 [==============================] - 1s 519us/step - loss: 0.4948 - accuracy: 0.7700\n",
            "Epoch 95/100\n",
            "1552/1552 [==============================] - 1s 525us/step - loss: 0.5055 - accuracy: 0.7564\n",
            "Epoch 96/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 0.4784 - accuracy: 0.7648\n",
            "Epoch 97/100\n",
            "1552/1552 [==============================] - 1s 522us/step - loss: 0.5161 - accuracy: 0.7564\n",
            "Epoch 98/100\n",
            "1552/1552 [==============================] - 1s 526us/step - loss: 0.5110 - accuracy: 0.7500\n",
            "Epoch 99/100\n",
            "1552/1552 [==============================] - 1s 521us/step - loss: 0.4702 - accuracy: 0.7719\n",
            "Epoch 100/100\n",
            "1552/1552 [==============================] - 1s 519us/step - loss: 0.4715 - accuracy: 0.7841\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7ff7828d5d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGvpT4DgFBDj",
        "colab_type": "code",
        "outputId": "6a26fcd2-b9cb-4787-ecc9-db6d3a7d347c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "predictions = []\n",
        "for row in y_pred:\n",
        "  predictions.append(np.argmax(row))\n",
        "a5 = accuracy_score(y_true, predictions)\n",
        "f1_5 = f1_score(y_true, predictions, average = 'weighted')\n",
        "print(\"Accuracy: \", a5)\n",
        "print(\"F1 score: \", f1_5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7917737789203085\n",
            "F1 score:  0.7922984048902975\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w_5Wf0kC9fC",
        "colab_type": "text"
      },
      "source": [
        "# Summary of different CNN models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TodGtF1Nr2t-",
        "colab_type": "code",
        "outputId": "82a294bd-0626-433e-8afd-6ea48f7a911b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "model1 = [\"Model 1\", a1, f1_1]\n",
        "model2 = [\"Model 2\", a2, f1_2]\n",
        "model3 = [\"Model 3\", a3, f1_3]\n",
        "model4 = [\"Model 4\", a4, f1_4]\n",
        "model5 = [\"Model 5\", a5, f1_5]\n",
        "data = [model1, model2, model3, model4, model5]\n",
        "df1 = pd.DataFrame(data, columns = ['CNN Model', 'Accuracy', 'F1 score'])\n",
        "df1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CNN Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Model 1</td>\n",
              "      <td>0.814910</td>\n",
              "      <td>0.815545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Model 2</td>\n",
              "      <td>0.817481</td>\n",
              "      <td>0.817417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Model 3</td>\n",
              "      <td>0.822622</td>\n",
              "      <td>0.822823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Model 4</td>\n",
              "      <td>0.786632</td>\n",
              "      <td>0.787396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Model 5</td>\n",
              "      <td>0.791774</td>\n",
              "      <td>0.792298</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  CNN Model  Accuracy  F1 score\n",
              "0   Model 1  0.814910  0.815545\n",
              "1   Model 2  0.817481  0.817417\n",
              "2   Model 3  0.822622  0.822823\n",
              "3   Model 4  0.786632  0.787396\n",
              "4   Model 5  0.791774  0.792298"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBscf8AiNaVQ",
        "colab_type": "text"
      },
      "source": [
        "## Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rRq-2CdT4Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "faces = []\n",
        "path= '/content/drive/My Drive/SMAI_Final_Assignment/Q2/final_test_data/test/'\n",
        "data = pd.read_csv('/content/drive/My Drive/SMAI_Final_Assignment/Q2/final_test.csv')\n",
        "for i in data['image_file']:\n",
        "    location = path + i + '.jpg'\n",
        "    location = location.strip()\n",
        "    img = cv2.imread(location, 0)\n",
        "    img = cv2.resize(img, (128, 128), interpolation = cv2.INTER_AREA)\n",
        "    faces.append(img)\n",
        "\n",
        "faces = np.array(faces)\n",
        "X_test = faces.reshape(faces.shape[0], 128, 128, 1)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa2ygzRgdaq6",
        "colab_type": "text"
      },
      "source": [
        "# Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ff9f3923-8cf0-4f84-9b2c-e63fddc26d23",
        "id": "0vNIi3_CdbCO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "faces = []\n",
        "path= '/content/drive/My Drive/SMAI_Final_Assignment/Q2/train/ntrain/'\n",
        "data = pd.read_csv('/content/drive/My Drive/SMAI_Final_Assignment/Q2/train_data.csv')\n",
        "for i in data['image_file']:\n",
        "    location = path + i + '.jpg'\n",
        "    location = location.strip()\n",
        "    img = cv2.imread(location, 0)\n",
        "    img = cv2.resize(img, (128,128), interpolation = cv2.INTER_AREA)\n",
        "    faces.append(img)\n",
        "\n",
        "faces = np.array(faces)\n",
        "X_train = faces.reshape(faces.shape[0], 128, 128, 1)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1941, 128, 128, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-3sDtyqGdbCx",
        "colab": {}
      },
      "source": [
        "y = []\n",
        "for i in data['emotion']:\n",
        "    y.append(i)\n",
        "\n",
        "number_of_classes = len(set(y))\n",
        "# print(number_of_classes)  \n",
        "y_train = np.array(y)\n",
        "y_train = y_train.astype('float32')\n",
        "y_train = keras.utils.to_categorical(y_train, number_of_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9bxwK7LzdbC7",
        "colab": {}
      },
      "source": [
        "X = X_train\n",
        "y = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ca4e413e-02de-4e9b-d627-a5f871736a71",
        "id": "dFA_Wc4DdbDE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "faces.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1941, 128, 128, 1)\n",
            "(1941, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1941, 128, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0ld80YPIdpxf",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(128, (3, 3), input_shape=(128, 128, 1), activation = 'relu'))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(5, activation = 'softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WL91rLBFdpyI",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0ade9426-97d6-4634-ad51-d767edf01a1b",
        "id": "_7MRqebtdpyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "predictions = []\n",
        "for row in y_pred:\n",
        "  predictions.append(np.argmax(row))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8149100257069408\n",
            "F1 score:  0.815544549151315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1wMjgZTHzgr",
        "colab_type": "text"
      },
      "source": [
        "# Saving predictions to a csv file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL2y-bxVdytd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "df = pd.DataFrame()\n",
        "df['emotion'] = predictions\n",
        "df.to_csv(\"submission.csv\",index=None)\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yItJO4GXd-mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp submission.csv \"drive/My Drive/smaiq2\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}